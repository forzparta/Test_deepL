{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import kornia as K\n",
        "import pytorch_lightning as pl\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from torchvision.models import resnet18, ResNet18_Weights\n",
        "import torch.nn.init as init\n",
        "import torchmetrics\n",
        "import torch.optim as optim\n",
        "import yaml\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#!pip install wandb -qU\n",
        "import wandb\n",
        "from pytorch_lightning.loggers import WandbLogger\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOeGFkeLfGcM"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Hog3sGYQaasb"
      },
      "outputs": [],
      "source": [
        "class PreProcess(nn.Module):\n",
        "    \"\"\"Module to perform pre-process using Kornia on torch tensors.\"\"\"\n",
        "    def __init__(self) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "    @torch.no_grad()  # disable gradients for effiency\n",
        "    def forward(self, x: Image) -> torch.Tensor:\n",
        "        x_tmp: np.ndarray = np.array(x)  # HxWxC\n",
        "        x_out: torch.Tensor = K.image_to_tensor(x_tmp, keepdim=True)  # CxHxW\n",
        "        x_out: K.enhance.Normalize(0.0, self._max_val)(x_out)\n",
        "        return x_out.float()\n",
        "    \n",
        "# Data Module for Lightning\n",
        "class CIFAR10DataModule(pl.LightningDataModule):\n",
        "    def __init__(self, batch_size=32):\n",
        "        super().__init__()\n",
        "        self.path = \"Python/Lightning_Resnet19/DataModules/datasets/CIFAR10\"\n",
        "        self.classes = 10\n",
        "        self.batch_size = batch_size\n",
        "        '''self.transform = transforms.Compose([\n",
        "            K.RandomHorizontalFlip(),\n",
        "            K.RandomVerticalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.5071, 0.4865, 0.4409), (0.2673, 0.2564, 0.2762))\n",
        "        ])'''\n",
        "        self.transform = PreProcess()\n",
        "\n",
        "    def prepare_data(self):\n",
        "        CIFAR10(root=self.path, train=True, download=True)\n",
        "        CIFAR10(root=self.path, train=False, download=True)\n",
        "\n",
        "    def setup(self, stage=None):\n",
        "        if stage == 'fit' or stage is None:\n",
        "            cifar10_full = CIFAR10(root=self.path, train=True, transform=self.transform)\n",
        "            self.train_dataset, self.val_dataset = random_split(cifar10_full, [45000, 5000])\n",
        "\n",
        "        if stage == 'test' or stage is None:\n",
        "            self.test_dataset = CIFAR10(root=self.path, train=False, transform=self.transform)\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True, num_workers=7, persistent_workers=True, pin_memory=True)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(self.val_dataset, batch_size=self.batch_size*4, num_workers=7, persistent_workers=True, pin_memory=True)\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return DataLoader(self.test_dataset, batch_size=self.batch_size*4, num_workers=7)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSKLETYGe6f5"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "7d-5gAXDajeG"
      },
      "outputs": [],
      "source": [
        "def initialize_weights(m):\n",
        "    if isinstance(m, nn.Conv2d):\n",
        "        init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
        "        if m.bias is not None:\n",
        "            init.constant_(m.bias, 0)\n",
        "    elif isinstance(m, nn.BatchNorm2d):\n",
        "        init.constant_(m.weight, 1)\n",
        "        init.constant_(m.bias, 0)\n",
        "    elif isinstance(m, nn.Linear):\n",
        "        init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
        "        init.constant_(m.bias, 0)\n",
        "\n",
        "# ResNet19_fc model\n",
        "class Resnet19_fc(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(Resnet19_fc, self).__init__()\n",
        "        self.epoch = 0\n",
        "        self.resnet_base = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
        "        num_ftrs = self.resnet_base.fc.in_features\n",
        "        self.resnet_base.fc = nn.Sequential(\n",
        "            nn.Linear(num_ftrs, num_ftrs // 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=0.2),\n",
        "            nn.Linear(num_ftrs // 2, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.resnet_base(x)\n",
        "\n",
        "# ResNet19_conv model\n",
        "class Resnet19_conv(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(Resnet19_conv, self).__init__()\n",
        "        self.epoch = 0\n",
        "        self.resnet_base = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
        "        additional_conv_layer = nn.Sequential(\n",
        "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU())\n",
        "        self.resnet_base.layer4.add_module(\"additional_conv_layer\", additional_conv_layer)\n",
        "        num_ftrs = self.resnet_base.fc.in_features\n",
        "        self.resnet_base.fc = nn.Linear(num_ftrs, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.resnet_base(x)\n",
        "\n",
        "class Basic_block(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(Basic_block, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_channels != out_channels:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, padding=0),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "        self.relu_out = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        out += self.shortcut(x)\n",
        "        out = self.relu_out(out)\n",
        "        return out\n",
        "\n",
        "class Resnet19_snn(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(Resnet19_snn, self).__init__()\n",
        "        self.epoch = 0\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 128, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(128)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        self.block1 = nn.Sequential(\n",
        "            Basic_block(128, 128, stride=1),\n",
        "            Basic_block(128, 128, stride=1),\n",
        "            Basic_block(128, 128, stride=1)\n",
        "        )\n",
        "\n",
        "        self.block2 = nn.Sequential(\n",
        "            Basic_block(128, 256, stride=2),\n",
        "            Basic_block(256, 256, stride=1),\n",
        "            Basic_block(256, 256, stride=1),\n",
        "        )\n",
        "\n",
        "        self.block3 = nn.Sequential(\n",
        "            Basic_block(256, 512, stride=2),\n",
        "            Basic_block(512, 512, stride=1)\n",
        "        )\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc1 = nn.Linear(512, 256)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(256, num_classes)\n",
        "        \n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.block1(x)\n",
        "        x = self.block2(x)\n",
        "        x = self.block3(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu2(x)\n",
        "        x = self.fc2(x)\n",
        "        \n",
        "        return x\n",
        "    \n",
        "def select_model(model_type, num_classes):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "    model_type (str): Type of the model ('fc', 'conv', or 'snn').\n",
        "    num_classes (int): Number of classes for the final output layer.\n",
        "    device: mps (mac), cuda, cpu.\n",
        "\n",
        "    Returns:\n",
        "    torch.nn.Module: The selected ResNet model.\n",
        "    \"\"\"\n",
        "    if model_type == 'fc':\n",
        "        model = Resnet19_fc(num_classes)\n",
        "    elif model_type == 'conv':\n",
        "        model = Resnet19_conv(num_classes)\n",
        "    elif model_type == 'snn':\n",
        "        model = Resnet19_snn(num_classes)\n",
        "        model.apply(initialize_weights)\n",
        "    else:\n",
        "        raise ValueError(\"Model type not found\")\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ov3PSPBQejFN"
      },
      "source": [
        "# Lit_module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "zwMy1bNad8eE",
        "outputId": "410b0769-ca82-4ed2-f9a6-323228d17770"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n        window._wandbApiKey = new Promise((resolve, reject) => {\n            function loadScript(url) {\n            return new Promise(function(resolve, reject) {\n                let newScript = document.createElement(\"script\");\n                newScript.onerror = reject;\n                newScript.onload = resolve;\n                document.body.appendChild(newScript);\n                newScript.src = url;\n            });\n            }\n            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n            const iframe = document.createElement('iframe')\n            iframe.style.cssText = \"width:0;height:0;border:none\"\n            document.body.appendChild(iframe)\n            const handshake = new Postmate({\n                container: iframe,\n                url: 'https://wandb.ai/authorize'\n            });\n            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n            handshake.then(function(child) {\n                child.on('authorize', data => {\n                    clearTimeout(timeout)\n                    resolve(data)\n                });\n            });\n            })\n        });\n    ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "class DataAugmentation(nn.Module):\n",
        "    \"\"\"Module to perform data augmentation using Kornia on torch tensors.\"\"\"\n",
        "\n",
        "    def __init__(self, apply_color_jitter: bool = False) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self._max_val: float = 255.0\n",
        "\n",
        "        self.transforms = nn.Sequential(#K.enhance.Normalize(0.0, self._max_val),\n",
        "                                        K.augmentation.RandomHorizontalFlip(p=0.5),\n",
        "                                        K.augmentation.RandomVerticalFlip(p=0.5))\n",
        "\n",
        "    @torch.no_grad()  # disable gradients for effiency\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x_out = self.transforms(x)  # BxCxHxW\n",
        "        return x_out\n",
        "    \n",
        "class ResNetLightningModule(pl.LightningModule):\n",
        "    def __init__(self, model, config, num_classes):\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "        self.config = config\n",
        "        self.transform = DataAugmentation()\n",
        "        # Metrics\n",
        "        self.train_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
        "        self.val_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
        "        self.test_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
        "        # Loss function\n",
        "        if self.config['loss'] == 'cross_entropy':\n",
        "            self.criterion = nn.CrossEntropyLoss()\n",
        "        self.save_hyperparameters(ignore=['model'])\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        x_aug = self.transform(x)\n",
        "        y_hat = self.forward(x_aug)\n",
        "        loss = self.criterion(y_hat, y)\n",
        "        self.log('train_loss', loss, prog_bar=True, on_step=False, on_epoch=True)\n",
        "        self.log('train_acc', self.train_acc(y_hat, y), prog_bar=True, on_step=False, on_epoch=True)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        y_hat = self.forward(x)\n",
        "        loss = self.criterion(y_hat, y)\n",
        "        self.log('val_loss', loss, prog_bar=True, on_step=False, on_epoch=True)\n",
        "        self.log('val_acc', self.val_acc(y_hat, y), prog_bar=True, on_step=False, on_epoch=True)\n",
        "        return loss\n",
        "    \n",
        "    def test_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        logits = self.forward(x)\n",
        "        acc = self.test_acc(logits, y)\n",
        "        self.log(\"test_acc\", acc)\n",
        "        return acc\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        if self.config['optimizer'] == 'adam':\n",
        "            optimizer = optim.Adam(self.model.parameters(), lr=self.config['lr'])\n",
        "        elif self.config['optimizer'] == 'sgd':\n",
        "            optimizer = optim.SGD(self.model.parameters(), lr=self.config['lr'],\n",
        "                                    momentum=self.config['momentum'],\n",
        "                                    weight_decay=self.config['weight_decay'])\n",
        "\n",
        "        if self.config['scheduler'] == 'step_lr':\n",
        "            scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=self.config['step_size'],\n",
        "                                                    gamma=self.config['gamma'])\n",
        "            return [optimizer], [scheduler]\n",
        "        return optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p3-rO31ZeYiu"
      },
      "source": [
        "# Main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RjvOpE-WkDxG"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "    pl.seed_everything(1)\n",
        "    wandb.login()\n",
        "\n",
        "    # Load config file\n",
        "    with open('Python/Lightning_Resnet19/config.yaml', 'r') as file:\n",
        "        config = yaml.safe_load(file)\n",
        "        \n",
        "    # Data Module\n",
        "    dm = CIFAR10DataModule()\n",
        "\n",
        "    # Model\n",
        "    model_name = 'snn'\n",
        "    num_classes = dm.classes#todo\n",
        "    model = select_model(model_name, num_classes)\n",
        "    #model_1 = resnet19.select_model('fc', num_classes, device)\n",
        "    #model_2 = resnet19.select_model('conv', num_classes, device)\n",
        "\n",
        "    # Lightning Module\n",
        "    lit_model = ResNetLightningModule(model, config, num_classes)\n",
        "\n",
        "    # Logger\n",
        "    wandb_logger = WandbLogger(project=\"lit_resnet19\", name = model_name, log_model=\"True\")\n",
        "    # Trainer\n",
        "    trainer = pl.Trainer(max_epochs=config['max_epochs'], logger=wandb_logger,\n",
        "                         callbacks=[ ModelCheckpoint(dirpath=\"./checkpoints\",\n",
        "                                             save_on_train_epoch_end=True,\n",
        "                                             filename='snn-{epoch}-loss:{val_loss:.2f}-acc:{val_acc:.2f}',\n",
        "                                             save_top_k = 3,\n",
        "                                             monitor=\"val_acc\", \n",
        "                                             mode=\"max\",\n",
        "                                             ),\n",
        "                                    ])\n",
        "    trainer.fit(lit_model, datamodule = dm)\n",
        "    wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
